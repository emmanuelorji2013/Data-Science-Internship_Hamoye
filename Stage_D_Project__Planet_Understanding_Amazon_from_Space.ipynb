{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage-D-Project_ Planet_Understanding-Amazon-from-Space.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelorji2013/Data-Science-Internship_Hamoye/blob/master/Stage_D_Project__Planet_Understanding_Amazon_from_Space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfyrQ7QpuWWR",
        "colab_type": "text"
      },
      "source": [
        "# Planet: Understanding Amazon from Space\n",
        "Implemented using KFold and VGG19 as the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2_wLLJ-SpSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff15db83-ff81-4636-b531-671b3e03a5b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGVgYqiPircX",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "01fb10d3-694c-4998-b429-668a7ad423a8"
      },
      "source": [
        "#upload the credentials of the kaggle account\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2415638f-8210-44f4-a28e-f1727e1d9407\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2415638f-8210-44f4-a28e-f1727e1d9407\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"emmybalance\",\"key\":\"c5316fb3d32955aa06253e6514067d56\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI9wn3d5m5c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle APU expects kaggle.json to be in ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permission change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0HAnYupm9yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8e1d5a7-8370-42c2-bd1e-043902a62d61"
      },
      "source": [
        "!kaggle datasets download  nikitarom/planets-dataset/ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading planets-dataset.zip to /content\n",
            " 99% 1.49G/1.50G [00:12<00:00, 142MB/s]\n",
            "100% 1.50G/1.50G [00:12<00:00, 126MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBw2u1tqnBcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0l81W9b0aTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir weights # Weights will be saved here for model checkpoint operation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-B23enBl_EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob, shutil\n",
        "\n",
        "# Combine test images into 1 folder (test-jpg)\n",
        "srcDir = \"test-jpg-additional/test-jpg-additional\"\n",
        "destDir = \"planet/planet/test-jpg\"\n",
        "for filePath in glob.glob(srcDir + '/*'):\n",
        "  # Move each file to destination Directory\n",
        "  shutil.move(filePath, destDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZAAfJLB1MBc",
        "colab_type": "text"
      },
      "source": [
        "## Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt-GFTt2mfIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, BatchNormalization\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Initializations\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 128\n",
        "input_channels = 3\n",
        "\n",
        "n_folds = 5\n",
        "\n",
        "training = True\n",
        "\n",
        "voting_ensemble = False  # If True, use voting for model ensemble, otherwise use averaging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7y707owgxHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_im_names = [os.path.splitext(filename)[0] for filename in os.listdir('planet/planet/test-jpg')]\n",
        "df_train_data = pd.read_csv('planet/planet/train_classes.csv')\n",
        "df_test_data = pd.DataFrame({ 'image_name': sorted(test_im_names), 'tags': \"\"})\n",
        "\n",
        "# Make a list of all possible labels\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "labels = list(set(flatten([l.split(' ') for l in df_train_data['tags'].values])))\n",
        "\n",
        "# Dictionary mapping labels to integer values 0-16\n",
        "map_labels = {l: i for i, l in enumerate(labels)}\n",
        "inv_map_labels = {i: l for l, i in map_labels.items()} # Inversion between keys and values in map_labels\n",
        "\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=1)\n",
        "\n",
        "fold_count = 0\n",
        "\n",
        "y_full_test = []\n",
        "thres_sum = np.zeros(17, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LW8eN8s3LoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a5f98175-b17a-4cca-fe2b-2c303e3cfd6f"
      },
      "source": [
        "print(\"There're {} labels\\n\".format(len(labels)))\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There're 17 labels\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blooming',\n",
              " 'agriculture',\n",
              " 'slash_burn',\n",
              " 'artisinal_mine',\n",
              " 'primary',\n",
              " 'selective_logging',\n",
              " 'water',\n",
              " 'partly_cloudy',\n",
              " 'conventional_mine',\n",
              " 'bare_ground',\n",
              " 'cultivation',\n",
              " 'clear',\n",
              " 'haze',\n",
              " 'habitation',\n",
              " 'blow_down',\n",
              " 'cloudy',\n",
              " 'road']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8G-8tCI2AL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "aaad3509-365c-495b-dc81-fe947c7cff8c"
      },
      "source": [
        "df_test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>file_0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>file_1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file_10</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>file_100</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>file_1000</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61186</th>\n",
              "      <td>test_9995</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61187</th>\n",
              "      <td>test_9996</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61188</th>\n",
              "      <td>test_9997</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61189</th>\n",
              "      <td>test_9998</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61190</th>\n",
              "      <td>test_9999</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61191 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_name tags\n",
              "0         file_0     \n",
              "1         file_1     \n",
              "2        file_10     \n",
              "3       file_100     \n",
              "4      file_1000     \n",
              "...          ...  ...\n",
              "61186  test_9995     \n",
              "61187  test_9996     \n",
              "61188  test_9997     \n",
              "61189  test_9998     \n",
              "61190  test_9999     \n",
              "\n",
              "[61191 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz-juiY40yRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9f145f1f-715f-461e-937e-23f19aeaccf2"
      },
      "source": [
        "df_train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>agriculture clear primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>agriculture clear habitation primary road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40474</th>\n",
              "      <td>train_40474</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40475</th>\n",
              "      <td>train_40475</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40476</th>\n",
              "      <td>train_40476</td>\n",
              "      <td>agriculture clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40477</th>\n",
              "      <td>train_40477</td>\n",
              "      <td>agriculture clear primary road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40478</th>\n",
              "      <td>train_40478</td>\n",
              "      <td>agriculture cultivation partly_cloudy primary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40479 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_name                                           tags\n",
              "0          train_0                                   haze primary\n",
              "1          train_1                agriculture clear primary water\n",
              "2          train_2                                  clear primary\n",
              "3          train_3                                  clear primary\n",
              "4          train_4      agriculture clear habitation primary road\n",
              "...            ...                                            ...\n",
              "40474  train_40474                                  clear primary\n",
              "40475  train_40475                                         cloudy\n",
              "40476  train_40476                      agriculture clear primary\n",
              "40477  train_40477                 agriculture clear primary road\n",
              "40478  train_40478  agriculture cultivation partly_cloudy primary\n",
              "\n",
              "[40479 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XAhdwOy5Sfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "27c61d28-84b2-47b7-f990-1856c9e48ad4"
      },
      "source": [
        "map_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agriculture': 1,\n",
              " 'artisinal_mine': 3,\n",
              " 'bare_ground': 9,\n",
              " 'blooming': 0,\n",
              " 'blow_down': 14,\n",
              " 'clear': 11,\n",
              " 'cloudy': 15,\n",
              " 'conventional_mine': 8,\n",
              " 'cultivation': 10,\n",
              " 'habitation': 13,\n",
              " 'haze': 12,\n",
              " 'partly_cloudy': 7,\n",
              " 'primary': 4,\n",
              " 'road': 16,\n",
              " 'selective_logging': 5,\n",
              " 'slash_burn': 2,\n",
              " 'water': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwWh6I_b6NOg",
        "colab_type": "text"
      },
      "source": [
        "## Split KFolds and train each fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb73Ko1foqqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55980f95-9fca-4e1d-e513-0b670f9ec35a"
      },
      "source": [
        "for train_index, test_index in kfold.split(df_train_data):\n",
        "\n",
        "    fold_count += 1\n",
        "    print('Fold ', fold_count)\n",
        "\n",
        "    df_train = df_train_data.loc[train_index]\n",
        "    if training:\n",
        "        print('----Will trian with {} samples ----'.format(len(df_train)))\n",
        "\n",
        "    df_valid = df_train_data.loc[test_index]\n",
        "    print('----Will validate with {} samples '.format(len(df_valid)))\n",
        "\n",
        "    #Custom train data generator\n",
        "    def train_generator():\n",
        "        while True:\n",
        "            for start in range(0, len(df_train), batch_size):\n",
        "                batch_x = []\n",
        "                batch_y = []\n",
        "                stop = min(start + batch_size, len(df_train))\n",
        "                df_train_batch = df_train[start:stop]\n",
        "                for f, tags in df_train_batch.values:\n",
        "                    image = cv2.imread('planet/planet/train-jpg/{}.jpg'.format(f))\n",
        "                    image = cv2.resize(image, (input_size, input_size))\n",
        "                    image = transformations(image, np.random.randint(6))\n",
        "                    targets = np.zeros(17)\n",
        "                    for t in tags.split(' '):\n",
        "                        targets[map_labels[t]] = 1\n",
        "                    batch_x.append(image)\n",
        "                    batch_y.append(targets)\n",
        "                batch_x = np.array(batch_x, np.float32)\n",
        "                batch_y = np.array(batch_y, np.uint8)\n",
        "                yield batch_x, batch_y\n",
        "\n",
        "    #Custom validation data generator\n",
        "    def valid_generator():\n",
        "        while True:\n",
        "            for start in range(0, len(df_valid), batch_size):\n",
        "                batch_x = []\n",
        "                batch_y = []\n",
        "                stop = min(start + batch_size, len(df_valid))\n",
        "                df_valid_batch = df_valid[start:stop]\n",
        "                for f, tags in df_valid_batch.values:\n",
        "                    image = cv2.imread('planet/planet/train-jpg/{}.jpg'.format(f))\n",
        "                    image = cv2.resize(image, (input_size, input_size))\n",
        "                    image = transformations(image, np.random.randint(6))\n",
        "                    targets = np.zeros(17)\n",
        "                    for t in tags.split(' '):\n",
        "                        targets[map_labels[t]] = 1\n",
        "                    batch_x.append(image)\n",
        "                    batch_y.append(targets)\n",
        "                batch_x = np.array(batch_x, np.float32)\n",
        "                batch_y = np.array(batch_y, np.uint8)\n",
        "                yield batch_x, batch_y\n",
        "\n",
        "\n",
        "    #Transformations for data augumentation\n",
        "    def transformations(src, choice):\n",
        "        if choice == 0:\n",
        "            # Rotate 90\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "        if choice == 1:\n",
        "            # Rotate 90 and flip horizontally\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "            src = cv2.flip(src, flipCode=1)\n",
        "        if choice == 2:\n",
        "            # Rotate 180\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_180)\n",
        "        if choice == 3:\n",
        "            # Rotate 180 and flip horizontally\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_180)\n",
        "            src = cv2.flip(src, flipCode=1)\n",
        "        if choice == 4:\n",
        "            # Rotate 90 counter-clockwise\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "        if choice == 5:\n",
        "            # Rotate 90 counter-clockwise and flip horizontally\n",
        "            src = cv2.rotate(src, rotateCode=cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "            src = cv2.flip(src, flipCode=1)\n",
        "        return src\n",
        "\n",
        "\n",
        "\n",
        "    base_model = VGG19(include_top=False,\n",
        "                       weights='imagenet',\n",
        "                       input_shape=(input_size, input_size, input_channels))\n",
        "\n",
        "    model = Sequential()\n",
        "    # Batchnorm input\n",
        "    model.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n",
        "    # Base model\n",
        "    model.add(base_model)\n",
        "    # Classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(17, activation='sigmoid'))\n",
        "\n",
        "    opt = Adam(lr=1e-4)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"CallBacks\")\n",
        "    callbacks = [EarlyStopping(monitor='val_loss',\n",
        "                               patience=4,\n",
        "                               verbose=1,\n",
        "                               min_delta=1e-4),\n",
        "                 ReduceLROnPlateau(monitor='val_loss',\n",
        "                                   factor=0.1,\n",
        "                                   patience=2,\n",
        "                                   cooldown=2,\n",
        "                                   verbose=1),\n",
        "                 ModelCheckpoint(filepath='weights/best_weights.fold_' + str(fold_count) + '.hdf5',\n",
        "                                 save_best_only=True,\n",
        "                                 save_weights_only=True)]\n",
        "\n",
        "    print(\"Training\")\n",
        "    if training:\n",
        "        model.fit(x=train_generator(),\n",
        "                            steps_per_epoch=(len(df_train) // batch_size) + 1,\n",
        "                            epochs=epochs,\n",
        "                            verbose=2,\n",
        "                            callbacks=callbacks,\n",
        "                            validation_data=valid_generator(),\n",
        "                            validation_steps=(len(df_valid) // batch_size) + 1)\n",
        "\n",
        "\n",
        "    def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
        "        def mf(x):\n",
        "            p2 = np.zeros_like(p)\n",
        "            for i in range(17):\n",
        "                p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
        "            score = fbeta_score(y, p2, beta=2, average='samples')\n",
        "            return score\n",
        "\n",
        "        x = [0.2] * 17\n",
        "        for i in range(17):\n",
        "            best_i2 = 0\n",
        "            best_score = 0\n",
        "            for i2 in range(resolution):\n",
        "                i2 /= float(resolution)\n",
        "                x[i] = i2\n",
        "                score = mf(x)\n",
        "                if score > best_score:\n",
        "                    best_i2 = i2\n",
        "                    best_score = score\n",
        "            x[i] = best_i2\n",
        "            if verbose:\n",
        "                print(i, best_i2, best_score)\n",
        "        return x\n",
        "\n",
        "    print(\"Load Weights\")\n",
        "    # Load best weights\n",
        "    model.load_weights(filepath='weights/best_weights.fold_' + str(fold_count) + '.hdf5')\n",
        "\n",
        "    valid_pred = model.predict(x=valid_generator(),\n",
        "                                      steps=(len(df_valid) // batch_size) + 1)\n",
        "\n",
        "    valid_y = []\n",
        "    for f, tags in df_valid.values:\n",
        "        targets = np.zeros(17)\n",
        "        for t in tags.split(' '):\n",
        "            targets[map_labels[t]] = 1\n",
        "        valid_y.append(targets)\n",
        "    valid_y = np.array(valid_y, np.uint8)\n",
        "\n",
        "    # Find optimal f2 thresholds for local validation set\n",
        "    thres = optimise_f2_thresholds(valid_y, valid_pred, verbose=False)\n",
        "\n",
        "    print('F2 = {}'.format(fbeta_score(valid_y, np.array(valid_pred) > thres, beta=2, average='samples')))\n",
        "\n",
        "    thres_sum += np.array(thres, np.float32)\n",
        "\n",
        "\n",
        "    def test_generator(transformation):\n",
        "        \n",
        "        while True:\n",
        "            for start in range(0, len(df_test_data), batch_size):\n",
        "                batch_x = []\n",
        "                stop = min(start + batch_size, len(df_test_data))\n",
        "                df_test_batch = df_test_data[start:stop]\n",
        "                for f, tags in df_test_batch.values:\n",
        "                    image = cv2.imread('planet/planet/test-jpg/{}.jpg'.format(f))\n",
        "                    image = cv2.resize(image, (input_size, input_size))\n",
        "                    image = transformations(image, transformation)\n",
        "                    batch_x.append(image)\n",
        "                    \n",
        "                batch_x = np.array(batch_x, np.float32)\n",
        "                yield batch_x\n",
        "\n",
        "    # 6-fold Test Time Augmentation\n",
        "    p_full_test = []\n",
        "    for i in range(6):\n",
        "      p_test = model.predict(x=test_generator(transformation=i),\n",
        "                                        steps=(len(df_test_data) // batch_size) + 1)\n",
        "      p_full_test.append(p_test)\n",
        "      \n",
        "\n",
        "    p_test = np.array(p_full_test[0])\n",
        "    for i in range(1, 6):\n",
        "        p_test += np.array(p_full_test[i])\n",
        "    p_test /= 6\n",
        "\n",
        "    y_full_test.append(p_test)\n",
        "\n",
        "result = np.array(y_full_test[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold  1\n",
            "----Will trian with 32383 samples ----\n",
            "----Will validate with 8096 samples \n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "CallBacks\n",
            "Training\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1644s vs `on_train_batch_end` time: 0.3963s). Check your callbacks.\n",
            "253/253 - 174s - loss: 0.1338 - accuracy: 0.5932 - val_loss: 0.1039 - val_accuracy: 0.5940\n",
            "Epoch 2/50\n",
            "253/253 - 173s - loss: 0.1020 - accuracy: 0.5978 - val_loss: 0.0972 - val_accuracy: 0.6014\n",
            "Epoch 3/50\n",
            "253/253 - 172s - loss: 0.0959 - accuracy: 0.6055 - val_loss: 0.0986 - val_accuracy: 0.6070\n",
            "Epoch 4/50\n",
            "253/253 - 172s - loss: 0.0923 - accuracy: 0.6094 - val_loss: 0.0946 - val_accuracy: 0.6109\n",
            "Epoch 5/50\n",
            "253/253 - 171s - loss: 0.0898 - accuracy: 0.6162 - val_loss: 0.0947 - val_accuracy: 0.6183\n",
            "Epoch 6/50\n",
            "253/253 - 172s - loss: 0.0879 - accuracy: 0.6173 - val_loss: 0.0931 - val_accuracy: 0.6291\n",
            "Epoch 7/50\n",
            "253/253 - 172s - loss: 0.0857 - accuracy: 0.6192 - val_loss: 0.0923 - val_accuracy: 0.6364\n",
            "Epoch 8/50\n",
            "253/253 - 171s - loss: 0.0846 - accuracy: 0.6216 - val_loss: 0.0937 - val_accuracy: 0.6546\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "253/253 - 171s - loss: 0.0837 - accuracy: 0.6238 - val_loss: 0.0937 - val_accuracy: 0.6364\n",
            "Epoch 10/50\n",
            "253/253 - 171s - loss: 0.0767 - accuracy: 0.6244 - val_loss: 0.0857 - val_accuracy: 0.6437\n",
            "Epoch 11/50\n",
            "253/253 - 171s - loss: 0.0740 - accuracy: 0.6344 - val_loss: 0.0852 - val_accuracy: 0.6467\n",
            "Epoch 12/50\n",
            "253/253 - 171s - loss: 0.0731 - accuracy: 0.6339 - val_loss: 0.0862 - val_accuracy: 0.6467\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "253/253 - 171s - loss: 0.0722 - accuracy: 0.6363 - val_loss: 0.0860 - val_accuracy: 0.6483\n",
            "Epoch 14/50\n",
            "253/253 - 172s - loss: 0.0706 - accuracy: 0.6393 - val_loss: 0.0851 - val_accuracy: 0.6412\n",
            "Epoch 15/50\n",
            "253/253 - 172s - loss: 0.0705 - accuracy: 0.6366 - val_loss: 0.0851 - val_accuracy: 0.6386\n",
            "Epoch 00015: early stopping\n",
            "Load Weights\n",
            "F2 = 0.929336497948016\n",
            "Fold  2\n",
            "----Will trian with 32383 samples ----\n",
            "----Will validate with 8096 samples \n",
            "CallBacks\n",
            "Training\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1884s vs `on_train_batch_end` time: 0.4572s). Check your callbacks.\n",
            "253/253 - 172s - loss: 0.1598 - accuracy: 0.5958 - val_loss: 0.1198 - val_accuracy: 0.5992\n",
            "Epoch 2/50\n",
            "253/253 - 173s - loss: 0.1116 - accuracy: 0.5880 - val_loss: 0.1075 - val_accuracy: 0.5719\n",
            "Epoch 3/50\n",
            "253/253 - 172s - loss: 0.1025 - accuracy: 0.5891 - val_loss: 0.0981 - val_accuracy: 0.6050\n",
            "Epoch 4/50\n",
            "253/253 - 172s - loss: 0.0979 - accuracy: 0.5921 - val_loss: 0.0958 - val_accuracy: 0.6102\n",
            "Epoch 5/50\n",
            "253/253 - 172s - loss: 0.0947 - accuracy: 0.5967 - val_loss: 0.0941 - val_accuracy: 0.6093\n",
            "Epoch 6/50\n",
            "253/253 - 173s - loss: 0.0927 - accuracy: 0.6057 - val_loss: 0.0937 - val_accuracy: 0.6155\n",
            "Epoch 7/50\n",
            "253/253 - 172s - loss: 0.0900 - accuracy: 0.6082 - val_loss: 0.0922 - val_accuracy: 0.6101\n",
            "Epoch 8/50\n",
            "253/253 - 173s - loss: 0.0886 - accuracy: 0.6116 - val_loss: 0.0921 - val_accuracy: 0.6231\n",
            "Epoch 9/50\n",
            "253/253 - 173s - loss: 0.0873 - accuracy: 0.6155 - val_loss: 0.0912 - val_accuracy: 0.6217\n",
            "Epoch 10/50\n",
            "253/253 - 171s - loss: 0.0860 - accuracy: 0.6193 - val_loss: 0.0929 - val_accuracy: 0.6336\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "253/253 - 171s - loss: 0.0848 - accuracy: 0.6222 - val_loss: 0.0919 - val_accuracy: 0.6416\n",
            "Epoch 12/50\n",
            "253/253 - 172s - loss: 0.0780 - accuracy: 0.6332 - val_loss: 0.0860 - val_accuracy: 0.6396\n",
            "Epoch 13/50\n",
            "253/253 - 173s - loss: 0.0762 - accuracy: 0.6342 - val_loss: 0.0857 - val_accuracy: 0.6360\n",
            "Epoch 14/50\n",
            "253/253 - 173s - loss: 0.0753 - accuracy: 0.6378 - val_loss: 0.0860 - val_accuracy: 0.6385\n",
            "Epoch 15/50\n",
            "253/253 - 172s - loss: 0.0748 - accuracy: 0.6388 - val_loss: 0.0853 - val_accuracy: 0.6433\n",
            "Epoch 16/50\n",
            "253/253 - 173s - loss: 0.0740 - accuracy: 0.6393 - val_loss: 0.0855 - val_accuracy: 0.6466\n",
            "Epoch 17/50\n",
            "253/253 - 172s - loss: 0.0734 - accuracy: 0.6433 - val_loss: 0.0851 - val_accuracy: 0.6418\n",
            "Epoch 18/50\n",
            "253/253 - 173s - loss: 0.0731 - accuracy: 0.6434 - val_loss: 0.0852 - val_accuracy: 0.6462\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "253/253 - 173s - loss: 0.0724 - accuracy: 0.6455 - val_loss: 0.0856 - val_accuracy: 0.6486\n",
            "Epoch 20/50\n",
            "253/253 - 172s - loss: 0.0711 - accuracy: 0.6474 - val_loss: 0.0842 - val_accuracy: 0.6504\n",
            "Epoch 21/50\n",
            "253/253 - 173s - loss: 0.0710 - accuracy: 0.6490 - val_loss: 0.0840 - val_accuracy: 0.6497\n",
            "Epoch 22/50\n",
            "253/253 - 173s - loss: 0.0708 - accuracy: 0.6493 - val_loss: 0.0846 - val_accuracy: 0.6504\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "253/253 - 171s - loss: 0.0706 - accuracy: 0.6476 - val_loss: 0.0843 - val_accuracy: 0.6482\n",
            "Epoch 24/50\n",
            "253/253 - 171s - loss: 0.0705 - accuracy: 0.6494 - val_loss: 0.0841 - val_accuracy: 0.6486\n",
            "Epoch 25/50\n",
            "253/253 - 172s - loss: 0.0705 - accuracy: 0.6497 - val_loss: 0.0840 - val_accuracy: 0.6480\n",
            "Epoch 00025: early stopping\n",
            "Load Weights\n",
            "F2 = 0.9292882708175318\n",
            "Fold  3\n",
            "----Will trian with 32383 samples ----\n",
            "----Will validate with 8096 samples \n",
            "CallBacks\n",
            "Training\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1811s vs `on_train_batch_end` time: 0.4504s). Check your callbacks.\n",
            "253/253 - 172s - loss: 0.1461 - accuracy: 0.5913 - val_loss: 0.1123 - val_accuracy: 0.5723\n",
            "Epoch 2/50\n",
            "253/253 - 172s - loss: 0.1061 - accuracy: 0.5999 - val_loss: 0.1012 - val_accuracy: 0.5976\n",
            "Epoch 3/50\n",
            "253/253 - 171s - loss: 0.0977 - accuracy: 0.5994 - val_loss: 0.0956 - val_accuracy: 0.6038\n",
            "Epoch 4/50\n",
            "253/253 - 171s - loss: 0.0932 - accuracy: 0.6049 - val_loss: 0.0943 - val_accuracy: 0.6087\n",
            "Epoch 5/50\n",
            "253/253 - 171s - loss: 0.0906 - accuracy: 0.6111 - val_loss: 0.0946 - val_accuracy: 0.5900\n",
            "Epoch 6/50\n",
            "253/253 - 171s - loss: 0.0887 - accuracy: 0.6150 - val_loss: 0.0932 - val_accuracy: 0.6319\n",
            "Epoch 7/50\n",
            "253/253 - 171s - loss: 0.0876 - accuracy: 0.6152 - val_loss: 0.0926 - val_accuracy: 0.6102\n",
            "Epoch 8/50\n",
            "253/253 - 171s - loss: 0.0861 - accuracy: 0.6237 - val_loss: 0.0925 - val_accuracy: 0.6328\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "253/253 - 171s - loss: 0.0844 - accuracy: 0.6207 - val_loss: 0.0927 - val_accuracy: 0.6370\n",
            "Epoch 10/50\n",
            "253/253 - 171s - loss: 0.0769 - accuracy: 0.6364 - val_loss: 0.0853 - val_accuracy: 0.6439\n",
            "Epoch 11/50\n",
            "253/253 - 171s - loss: 0.0752 - accuracy: 0.6409 - val_loss: 0.0846 - val_accuracy: 0.6449\n",
            "Epoch 12/50\n",
            "253/253 - 171s - loss: 0.0741 - accuracy: 0.6402 - val_loss: 0.0850 - val_accuracy: 0.6513\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "253/253 - 171s - loss: 0.0735 - accuracy: 0.6410 - val_loss: 0.0851 - val_accuracy: 0.6449\n",
            "Epoch 14/50\n",
            "253/253 - 171s - loss: 0.0719 - accuracy: 0.6472 - val_loss: 0.0842 - val_accuracy: 0.6459\n",
            "Epoch 15/50\n",
            "253/253 - 171s - loss: 0.0715 - accuracy: 0.6443 - val_loss: 0.0842 - val_accuracy: 0.6445\n",
            "Epoch 16/50\n",
            "253/253 - 171s - loss: 0.0714 - accuracy: 0.6444 - val_loss: 0.0841 - val_accuracy: 0.6474\n",
            "Epoch 17/50\n",
            "253/253 - 171s - loss: 0.0714 - accuracy: 0.6456 - val_loss: 0.0840 - val_accuracy: 0.6438\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "253/253 - 171s - loss: 0.0711 - accuracy: 0.6440 - val_loss: 0.0846 - val_accuracy: 0.6444\n",
            "Epoch 19/50\n",
            "253/253 - 171s - loss: 0.0709 - accuracy: 0.6450 - val_loss: 0.0838 - val_accuracy: 0.6455\n",
            "Epoch 20/50\n",
            "253/253 - 171s - loss: 0.0709 - accuracy: 0.6454 - val_loss: 0.0840 - val_accuracy: 0.6455\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "253/253 - 172s - loss: 0.0709 - accuracy: 0.6442 - val_loss: 0.0842 - val_accuracy: 0.6430\n",
            "Epoch 22/50\n",
            "253/253 - 171s - loss: 0.0708 - accuracy: 0.6456 - val_loss: 0.0842 - val_accuracy: 0.6456\n",
            "Epoch 23/50\n",
            "253/253 - 171s - loss: 0.0709 - accuracy: 0.6443 - val_loss: 0.0841 - val_accuracy: 0.6438\n",
            "Epoch 00023: early stopping\n",
            "Load Weights\n",
            "F2 = 0.9313454756902505\n",
            "Fold  4\n",
            "----Will trian with 32383 samples ----\n",
            "----Will validate with 8096 samples \n",
            "CallBacks\n",
            "Training\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1833s vs `on_train_batch_end` time: 0.4552s). Check your callbacks.\n",
            "253/253 - 172s - loss: 0.1368 - accuracy: 0.5891 - val_loss: 0.1056 - val_accuracy: 0.5660\n",
            "Epoch 2/50\n",
            "253/253 - 173s - loss: 0.1032 - accuracy: 0.5868 - val_loss: 0.0974 - val_accuracy: 0.5936\n",
            "Epoch 3/50\n",
            "253/253 - 173s - loss: 0.0971 - accuracy: 0.5911 - val_loss: 0.0951 - val_accuracy: 0.5828\n",
            "Epoch 4/50\n",
            "253/253 - 172s - loss: 0.0931 - accuracy: 0.5988 - val_loss: 0.0928 - val_accuracy: 0.5952\n",
            "Epoch 5/50\n",
            "253/253 - 172s - loss: 0.0906 - accuracy: 0.6077 - val_loss: 0.0937 - val_accuracy: 0.5835\n",
            "Epoch 6/50\n",
            "253/253 - 172s - loss: 0.0888 - accuracy: 0.6080 - val_loss: 0.0914 - val_accuracy: 0.6045\n",
            "Epoch 7/50\n",
            "253/253 - 172s - loss: 0.0872 - accuracy: 0.6125 - val_loss: 0.0914 - val_accuracy: 0.6099\n",
            "Epoch 8/50\n",
            "253/253 - 172s - loss: 0.0852 - accuracy: 0.6119 - val_loss: 0.0908 - val_accuracy: 0.6072\n",
            "Epoch 9/50\n",
            "253/253 - 174s - loss: 0.0842 - accuracy: 0.6210 - val_loss: 0.0906 - val_accuracy: 0.6114\n",
            "Epoch 10/50\n",
            "253/253 - 173s - loss: 0.0829 - accuracy: 0.6217 - val_loss: 0.0917 - val_accuracy: 0.6217\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "253/253 - 173s - loss: 0.0820 - accuracy: 0.6250 - val_loss: 0.0945 - val_accuracy: 0.6070\n",
            "Epoch 12/50\n",
            "253/253 - 174s - loss: 0.0749 - accuracy: 0.6343 - val_loss: 0.0854 - val_accuracy: 0.6361\n",
            "Epoch 13/50\n",
            "253/253 - 174s - loss: 0.0727 - accuracy: 0.6387 - val_loss: 0.0860 - val_accuracy: 0.6417\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "253/253 - 174s - loss: 0.0715 - accuracy: 0.6399 - val_loss: 0.0857 - val_accuracy: 0.6444\n",
            "Epoch 15/50\n",
            "253/253 - 173s - loss: 0.0700 - accuracy: 0.6460 - val_loss: 0.0848 - val_accuracy: 0.6409\n",
            "Epoch 16/50\n",
            "253/253 - 174s - loss: 0.0696 - accuracy: 0.6453 - val_loss: 0.0847 - val_accuracy: 0.6387\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "253/253 - 174s - loss: 0.0697 - accuracy: 0.6441 - val_loss: 0.0856 - val_accuracy: 0.6354\n",
            "Epoch 18/50\n",
            "253/253 - 174s - loss: 0.0692 - accuracy: 0.6444 - val_loss: 0.0846 - val_accuracy: 0.6382\n",
            "Epoch 19/50\n",
            "253/253 - 174s - loss: 0.0694 - accuracy: 0.6443 - val_loss: 0.0849 - val_accuracy: 0.6383\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "253/253 - 174s - loss: 0.0696 - accuracy: 0.6438 - val_loss: 0.0847 - val_accuracy: 0.6409\n",
            "Epoch 21/50\n",
            "253/253 - 174s - loss: 0.0691 - accuracy: 0.6441 - val_loss: 0.0850 - val_accuracy: 0.6370\n",
            "Epoch 22/50\n",
            "253/253 - 174s - loss: 0.0692 - accuracy: 0.6427 - val_loss: 0.0845 - val_accuracy: 0.6378\n",
            "Epoch 23/50\n",
            "253/253 - 174s - loss: 0.0690 - accuracy: 0.6442 - val_loss: 0.0845 - val_accuracy: 0.6362\n",
            "Epoch 24/50\n",
            "253/253 - 175s - loss: 0.0692 - accuracy: 0.6445 - val_loss: 0.0843 - val_accuracy: 0.6376\n",
            "Epoch 25/50\n",
            "253/253 - 174s - loss: 0.0693 - accuracy: 0.6443 - val_loss: 0.0849 - val_accuracy: 0.6395\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "253/253 - 174s - loss: 0.0693 - accuracy: 0.6439 - val_loss: 0.0847 - val_accuracy: 0.6391\n",
            "Epoch 27/50\n",
            "253/253 - 174s - loss: 0.0692 - accuracy: 0.6448 - val_loss: 0.0847 - val_accuracy: 0.6387\n",
            "Epoch 28/50\n",
            "253/253 - 174s - loss: 0.0694 - accuracy: 0.6446 - val_loss: 0.0845 - val_accuracy: 0.6371\n",
            "Epoch 00028: early stopping\n",
            "Load Weights\n",
            "F2 = 0.9302207513651376\n",
            "Fold  5\n",
            "----Will trian with 32384 samples ----\n",
            "----Will validate with 8095 samples \n",
            "CallBacks\n",
            "Training\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1834s vs `on_train_batch_end` time: 0.4364s). Check your callbacks.\n",
            "254/254 - 175s - loss: 0.1493 - accuracy: 0.5974 - val_loss: 0.1119 - val_accuracy: 0.6149\n",
            "Epoch 2/50\n",
            "254/254 - 174s - loss: 0.1088 - accuracy: 0.6002 - val_loss: 0.0993 - val_accuracy: 0.6103\n",
            "Epoch 3/50\n",
            "254/254 - 174s - loss: 0.1002 - accuracy: 0.6062 - val_loss: 0.0966 - val_accuracy: 0.6130\n",
            "Epoch 4/50\n",
            "254/254 - 174s - loss: 0.0962 - accuracy: 0.6121 - val_loss: 0.0951 - val_accuracy: 0.6170\n",
            "Epoch 5/50\n",
            "254/254 - 173s - loss: 0.0928 - accuracy: 0.6180 - val_loss: 0.0932 - val_accuracy: 0.6308\n",
            "Epoch 6/50\n",
            "254/254 - 174s - loss: 0.0906 - accuracy: 0.6218 - val_loss: 0.0930 - val_accuracy: 0.6341\n",
            "Epoch 7/50\n",
            "254/254 - 173s - loss: 0.0893 - accuracy: 0.6245 - val_loss: 0.0929 - val_accuracy: 0.6094\n",
            "Epoch 8/50\n",
            "254/254 - 173s - loss: 0.0875 - accuracy: 0.6259 - val_loss: 0.0908 - val_accuracy: 0.6222\n",
            "Epoch 9/50\n",
            "254/254 - 172s - loss: 0.0862 - accuracy: 0.6375 - val_loss: 0.0914 - val_accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "254/254 - 173s - loss: 0.0847 - accuracy: 0.6320 - val_loss: 0.0911 - val_accuracy: 0.6106\n",
            "Epoch 11/50\n",
            "254/254 - 173s - loss: 0.0776 - accuracy: 0.6353 - val_loss: 0.0853 - val_accuracy: 0.6371\n",
            "Epoch 12/50\n",
            "254/254 - 173s - loss: 0.0758 - accuracy: 0.6445 - val_loss: 0.0850 - val_accuracy: 0.6421\n",
            "Epoch 13/50\n",
            "254/254 - 173s - loss: 0.0750 - accuracy: 0.6466 - val_loss: 0.0849 - val_accuracy: 0.6452\n",
            "Epoch 14/50\n",
            "254/254 - 173s - loss: 0.0743 - accuracy: 0.6501 - val_loss: 0.0845 - val_accuracy: 0.6484\n",
            "Epoch 15/50\n",
            "254/254 - 173s - loss: 0.0737 - accuracy: 0.6538 - val_loss: 0.0844 - val_accuracy: 0.6505\n",
            "Epoch 16/50\n",
            "254/254 - 173s - loss: 0.0731 - accuracy: 0.6537 - val_loss: 0.0847 - val_accuracy: 0.6536\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "254/254 - 173s - loss: 0.0726 - accuracy: 0.6523 - val_loss: 0.0851 - val_accuracy: 0.6506\n",
            "Epoch 18/50\n",
            "254/254 - 173s - loss: 0.0712 - accuracy: 0.6513 - val_loss: 0.0845 - val_accuracy: 0.6523\n",
            "Epoch 19/50\n",
            "254/254 - 173s - loss: 0.0710 - accuracy: 0.6536 - val_loss: 0.0840 - val_accuracy: 0.6542\n",
            "Epoch 20/50\n",
            "254/254 - 174s - loss: 0.0707 - accuracy: 0.6527 - val_loss: 0.0838 - val_accuracy: 0.6539\n",
            "Epoch 21/50\n",
            "254/254 - 173s - loss: 0.0707 - accuracy: 0.6529 - val_loss: 0.0840 - val_accuracy: 0.6524\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "254/254 - 173s - loss: 0.0705 - accuracy: 0.6552 - val_loss: 0.0843 - val_accuracy: 0.6534\n",
            "Epoch 23/50\n",
            "254/254 - 173s - loss: 0.0704 - accuracy: 0.6554 - val_loss: 0.0840 - val_accuracy: 0.6540\n",
            "Epoch 24/50\n",
            "254/254 - 173s - loss: 0.0703 - accuracy: 0.6557 - val_loss: 0.0840 - val_accuracy: 0.6551\n",
            "Epoch 00024: early stopping\n",
            "Load Weights\n",
            "F2 = 0.9305772277939591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk-OnVx37msO",
        "colab_type": "text"
      },
      "source": [
        "## Model Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbmQplAN8Lkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if voting_ensemble:\n",
        "    for f in range(len(y_full_test[0])):  # For each file\n",
        "        for tag in range(17):  # For each tag\n",
        "            preds = []\n",
        "            for fold in range(n_folds):  # For each fold\n",
        "                preds.append(y_full_test[fold][f][tag])\n",
        "            pred = Counter(preds).most_common(1)[0][0]  # Most common tag prediction among folds\n",
        "            result[f][tag] = pred\n",
        "else:\n",
        "    for fold in range(1, n_folds):\n",
        "        result += np.array(y_full_test[fold])\n",
        "    result /= n_folds\n",
        "result = pd.DataFrame(result, columns=labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvO2AllOUBDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "addad5ac-b863-4fc2-cf25-144622e53230"
      },
      "source": [
        "preds = []\n",
        "thres = (thres_sum / n_folds).tolist()\n",
        "\n",
        "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
        "    a = result.loc[[i]]\n",
        "    a = a.apply(lambda x: x > thres, axis=1)\n",
        "    a = a.transpose()\n",
        "    a = a.loc[a[i] == True]\n",
        "    ' '.join(list(a.index))\n",
        "    preds.append(' '.join(list(a.index)))\n",
        "\n",
        "df_test_data['tags'] = preds\n",
        "submsnDest = r\"/content/drive/My Drive/Colab Notebooks/Hamoye Internship/\"\n",
        "df_test_data.to_csv(\"{}/submission.csv\".format(submsnDest), index=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61191/61191 [03:10<00:00, 321.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZmeXp5mNrXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}